{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('房产_链家二手房_北京_2014-2021.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df = df.rename(columns={'Transaction_Time）':'Transaction_Time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values with mean\n",
    "df['Transaction_Cycle(day)'] = df['Transaction_Cycle(day)'].fillna(df['Transaction_Cycle(day)'].mean())\n",
    "df['Average_Price'] = df['Average_Price'].fillna(df['Average_Price'].mean())\n",
    "df['Building_Year'] = df['Building_Year'].fillna(df['Building_Year'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data\n",
    "df['Building_Year'] = df['Building_Year'].astype(np.int64)\n",
    "df['Transaction_Cycle(day)'] = df['Transaction_Cycle(day)'].astype(np.int64)\n",
    "df['Average_Price'] = df['Average_Price'].astype(np.int64)\n",
    "df['Transaction_Time'] = pd.to_datetime(df['Transaction_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check date information again\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical fields\n",
    "df['Floor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Floor','Building_Type','Building_structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Floor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Building_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Renovation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elevator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duty_Free'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subway_or_not'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['District'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Floor'].replace(['底层', '底楼层', '顶层', '高楼层', '中楼层'],['Bottom','Low','Middle','High','Top'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Building_Type'].replace(['板楼', '板塔结合', '塔楼', '平房'],['Slab_building','Slab_building_mixed_tower','Building_like_tower','Bungalow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Renovation'].replace(['简装', '精装', '其他', '毛坯'],['Fine_decoration','Delicate_decoration','Others','No_decoration'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Building_structure'].replace(['混合结构', '钢混结构', '砖混结构', '砖木结构', '钢结构'],['Mixed_structure','Steel-concrete_structure','Brick_structure','Brick_and_wood_structure','Steel_structure'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elevator'].replace(['无', '有'],['Yes','No'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duty_Free'].replace('满五年','Yes',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subway_or_not'].replace(['否', '是'],['No','Yes'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['District'].replace(['石景山', '海淀', '昌平', '西城', '顺义', '朝阳', '丰台', '东城', '通州', '平谷', '大兴',\n",
    "       '门头沟','房山'],['SJ','HD','CP','XC','SY','CY','FT','DC','TZ','PG','DX','MTG','FS'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove data with wrong date(Select data by time range)\n",
    "s_date = '2014-01-01'\n",
    "e_date = '2021-12-31'\n",
    "df = df[(df['Transaction_Time'] >= s_date) & (df['Transaction_Time'] <= e_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv before encoding\n",
    "#df.to_csv('C:/Python/Practice5005/df_clean1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "df_1 = df\n",
    "df_1['Floor'].replace(['Bottom','Low','Middle','High','Top'],[0,1,2,3,4],inplace=True)\n",
    "df_1['Building_Type'].replace(['Slab_building','Slab_building_mixed_tower','Building_like_tower','Bungalow'],[3,2,1,0],inplace=True)\n",
    "df_1['Renovation'].replace(['Fine_decoration','Delicate_decoration','Others','No_decoration'],[2,3,1,0],inplace=True)\n",
    "df_1['Building_structure'].replace(['Mixed_structure','Steel-concrete_structure','Brick_structure','Brick_and_wood_structure','Steel_structure'],[2,3,1,0,4],inplace=True)\n",
    "df_1['Elevator'].replace(['Yes','No'],[1,0],inplace=True)\n",
    "df_1['Subway_or_not'].replace(['No','Yes'],[0,1],inplace=True)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_price = df_1.groupby('District')['Average_Price'].mean()\n",
    "dis_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dis_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = pd.DataFrame(dis_price, columns=['Average_Price'])\n",
    "dis.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x =dis.index ,height=dis['Average_Price'])\n",
    "plt.title('Average house price by different regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['District'].replace(['SJ','HD','CP','XC','SY','CY','FT','DC','TZ','PG','DX','MTG','FS'],[7,10,3,12,2,9,8,11,6,4,5,1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv after encoding\n",
    "#df_1.to_csv('C:/Python/Practice5005/df_clean2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features\n",
    "df_fa = df_1.drop(columns = ['ID','Duty_Free','Transaction_Time','Price_PerSquare','BedRoom','SittingRoom','Bathroom','Kitchen','Average_Price','Building_Height'])\n",
    "df_fa.dropna()\n",
    "df_fa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_fa)\n",
    "chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df_fa)\n",
    "print(kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "fa = FactorAnalyzer(df_fa.shape[1]+1, rotation=None)\n",
    "fa.fit(df_fa)\n",
    "ev, v = fa.get_eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(range(1,df_fa.shape[1]+1),ev)\n",
    "plt.plot(range(1,df_fa.shape[1]+1),ev)\n",
    "plt.title('scree plot',fontdict={'weight':'normal','size': 25})\n",
    "plt.xlabel('Fa_score.csvactor',fontdict={'weight':'normal','size': 15})\n",
    "plt.ylabel('Eigenvalues',fontdict={'weight':'normal','size': 15})\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = sum(ev>=1)\n",
    "n_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the rotated result\n",
    "fa2 = FactorAnalyzer(n_factors,rotation='varimax',method='principal')\n",
    "fa2.fit(df_fa)\n",
    "#Give the contribution rate\n",
    "var = fa2.get_factor_variance()\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa2.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_fa_loading = pd.DataFrame(fa2.loadings_,index=df_fa.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(df_fa_loading,annot=True,cmap='BuPu',ax=ax)\n",
    "ax.tick_params(axis='x',labelsize=15)\n",
    "ax.set_title(\"Factor Analysis\",fontsize=12)\n",
    "ax.set_ylabel(\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa_loading.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa2_score = fa2.transform(df_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['fac'+str(i) for i in np.arange(n_factors)+1]\n",
    "fa_score_df = pd.DataFrame(fa2_score,columns=column_list)\n",
    "for col in fa_score_df.columns:\n",
    "    df_fa[col] = fa_score_df[col]\n",
    "fa_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = fa2_score.shape\n",
    "feature_names = fa_score_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try model_1 by default para\n",
    "model_1 = DBSCAN().fit(fa2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fa2_score[:,0],fa2_score[:,1],c=model_1.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select better para(eps,min_samples)\n",
    "res=[]\n",
    "lit=[500,1000,2000,3000]\n",
    "\n",
    "for Eps in np.arange(0.65,0.85,0.05):\n",
    "    for Min_samples in lit:\n",
    "        model = DBSCAN(eps=Eps,min_samples=Min_samples).fit(fa2_score)\n",
    "        n_clusters = len([i for i in set(model.labels_) if i != -1])\n",
    "        outliners = np.sum(np.where(model.labels_ == -1))\n",
    "        res.append({'eps':Eps,'min_samples':Min_samples,'n_clusters':n_clusters,'outliners':outliners})\n",
    "df_res = pd.DataFrame(res)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model based on eps=0.5,min_samples=1000\n",
    "model_2 = DBSCAN(eps=0.5,min_samples=1000).fit(fa2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model_2.labels_))\n",
    "print(model_2.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(fa2_score[:,2],fa2_score[:,3],c=model_2.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the numbers of different clusters\n",
    "from collections import Counter\n",
    "clusters = Counter(model_2.labels_)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = model_2.labels_\n",
    "plt.scatter(df_geo['Longitude'],df_geo['Latitude'],c=colors)\n",
    "plt.xlabel('Longitude',family = 'Arial',fontsize=9)\n",
    "plt.ylabel('Latitude',family = 'Arial',fontsize=9)\n",
    "plt.title('Clusters of houses in Beijing based on DBSCAN',family = 'Arial',fontsize=15)\n",
    "plt.grid(which='major',color='#cccccc',alpha=0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert model labels（array format) into dataframe\n",
    "df_label = pd.DataFrame(model_2.labels_)\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['label'] = df_label[0]\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check features of the different clusters\n",
    "df_1.groupby('label')['Transaction_Cycle(day)','Followers','Price_PerSquare','Area','BedRoom','SittingRoom','Kitchen', 'Bathroom', 'Floor',\n",
    "       'Building_Height', 'Building_Type', 'Building_Year', 'Renovation',\n",
    "       'Building_structure', 'Elevator_Ratio', 'Elevator', 'Duty_Free',\n",
    "       'Subway_or_not', 'District', 'Average_Price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different group numbers for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for i in range(3,7):\n",
    "    km = KMeans(n_clusters=i).fit(fa2_score)\n",
    "    rs_labels = km.labels_\n",
    "    label_series=pd.Series(rs_labels)\n",
    "    print(\" %s clusters and counts are:\" % i)\n",
    "    print(label_series.value_counts())\n",
    "    # print(\"Cluster centers are:\")\n",
    "    # print(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when k is equal to 5, the features of cluster_1 are similar to high-end apartments.\n",
    "km_2 = KMeans(n_clusters=5).fit(fa2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['label_1']=km_2.labels_\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1.groupby('label_1')['Transaction_Time',\n",
    "       'Transaction_Cycle(day)', 'Followers', 'Total_Price', 'Price_PerSquare',\n",
    "       'Area', 'BedRoom', 'SittingRoom', 'Kitchen', 'Bathroom', 'Floor',\n",
    "       'Building_Height', 'Building_Type', 'Building_Year', 'Renovation',\n",
    "       'Building_structure', 'Elevator_Ratio', 'Elevator', 'Duty_Free',\n",
    "       'Subway_or_not', 'District', 'Average_Price',].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_1['label_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1.to_csv('C:/Python/Practice5005/df_cluster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Clustering based on location('Longitude', 'Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14,9  #set plot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.read_csv('C:/Python/practice5005/df_cluster.csv',usecols=['ID','Longitude','Latitude','label_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df_geo.loc[df_geo['label_1'] == 1]\n",
    "print(df_high.head())\n",
    "print(len(df_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the geographical points\n",
    "_ = plt.plot(df_high['Longitude'],df_high['Latitude'],marker='.',linewidth=0,color='#128128')\n",
    "_ = plt.grid(which='major',color='#cccccc',alpha=0.45)\n",
    "_ = plt.title('Geographical distribution of high-end houses in Beijing',family='Arial',fontsize=12)\n",
    "_ = plt.xlabel('Longitude')\n",
    "_ = plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_high[['Longitude','Latitude']]\n",
    "df_cluster = df_cluster.values.astype('float32',copy=False)\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normaliza data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model_scaler = StandardScaler().fit(df_cluster)\n",
    "df_cluster_scaler = model_scaler.transform(df_cluster)\n",
    "df_cluster_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1=[]\n",
    "lit_1=[500,1000,2000,3000]\n",
    "\n",
    "for Eps in np.arange(0.25,0.45,0.05):\n",
    "    for Min_samples in lit_1:\n",
    "        model = DBSCAN(eps=Eps,min_samples=Min_samples).fit(df_cluster_scaler)\n",
    "        n_clusters = len([i for i in set(model.labels_) if i != -1])\n",
    "        outliners = np.sum(np.where(model.labels_ == -1))\n",
    "        res_1.append({'eps':Eps,'min_samples':Min_samples,'n_clusters':n_clusters,'outliners':outliners})\n",
    "df_res_1 = pd.DataFrame(res_1)\n",
    "df_res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model based on normaliza data\n",
    "model_3 = DBSCAN(eps=0.25,min_samples=1000).fit(df_cluster_scaler)\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "clusters_3 = Counter(model_3.labels_)\n",
    "clusters_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors3 = model_3.labels_\n",
    "plt.scatter(df_high['Longitude'],df_high['Latitude'],c=colors3)\n",
    "plt.xlabel('Longitude',family = 'Arial',fontsize=9)\n",
    "plt.ylabel('Latitude',family = 'Arial',fontsize=9)\n",
    "plt.title('Clusters of houses in Beijing based on DBSCAN',family = 'Arial',fontsize=15)\n",
    "plt.grid(which='major',color='#cccccc',alpha=0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high['label_2']=model_3.labels_\n",
    "df_high.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df_high to csv\n",
    "df_high.to_csv('C:/Python/Practice5005/df_high.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot in map\n",
    "#pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import ArcGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beijian = ArcGIS().geocode('beijing')\n",
    "Beijian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "bj_map = folium.Map(location=[39.90750000000003, 116.39723000000004],zoom_start=8)\n",
    "bj_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = df_high[['ID','Longitude','Latitude','label_1']].values.tolist()\n",
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "bj_map1 = folium.Map(location=[39.98317261,116.4134249])\n",
    "fg = folium.FeatureGroup(name='Clusters of houses in Beijing based on DBSCAN in the map')\n",
    "\n",
    "for i in a_list:\n",
    "    fg.add_child(folium.Marker(location=[i[2],i[1]],popup=i[3],icon=folium.Icon(color=i[3])))\n",
    "bj_map1.add_child(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data in 2014\n",
    "#s_2014 = '2014-01-01'\n",
    "#e_2015 = '2015-12-31'\n",
    "#df_1415 = df[(df['Transaction_Time'] >= s_2014) & (df['Transaction_Time'] <= e_2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized data\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#df_cluster=scaler.fit_transform(df_fa)\n",
    "#df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After normalization, the data categories become array\n",
    "#type(df_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
